{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4. Matrix and Vector Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.Read about Broadcasting with Arrays on the chapter Computation on Arrays: Broadcasting from Python Data Science Handbook (J. VandePlas, 2016): Link: https://jakevdp.github.io/PythonDataScienceHandbook/02.03-computation-on-arrays-ufuncs.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section from the Python Data Science Handbook discusses the importance of vectorized operations in NumPy for efficient computation, particularly through universal functions (ufuncs). It explains the slowness of loops in Python and introduces ufuncs as a solution for faster array computations. \n",
    "\n",
    "The document covers unary and binary ufuncs, arithmetic and trigonometric operations, absolute values, exponents, and logarithms. It also explores specialized ufuncs, output specification, aggregates, and outer products, detailing how these features can enhance computation efficiency and capability in NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Read Rewriting the particle simulator in Numpy on Chapter 2: Fast Array Operations with Numpy and Pandas (pp. 68) from the book G. Lenaro (2017). Python high Performance. Second Edition. UK: Packt Publishing Ltd. \n",
    "\n",
    "#### Implement the improvements on the particle simulator using NumPy. Show that both implementations scale linearly with particle size, but the runtime in the pure Python version grows much faster than the NumPy version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking with 100 particles:\n",
      "Python version: 0.3331199989988818 seconds\n",
      "NumPy version: 0.09139973599667428 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import uniform\n",
    " \n",
    "class Particle:\n",
    "    def __init__(self, x, y, ang_vel):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.ang_vel = ang_vel\n",
    " \n",
    "class ParticleSimulator:\n",
    "    def __init__(self, particles):\n",
    "        self.particles = particles\n",
    " \n",
    "    def evolve_python(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    " \n",
    "        for i in range(nsteps):\n",
    "            for p in self.particles:\n",
    "                norm = (p.x**2 + p.y**2)**0.5\n",
    "                v_x = (-p.y) / norm\n",
    "                v_y = p.x / norm\n",
    "                d_x = timestep * p.ang_vel * v_x\n",
    "                d_y = timestep * p.ang_vel * v_y\n",
    "                p.x += d_x\n",
    "                p.y += d_y\n",
    " \n",
    "    def evolve_numpy(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    "        r_i = np.array([[p.x, p.y] for p in self.particles])\n",
    "        ang_vel_i = np.array([p.ang_vel for p in self.particles])\n",
    " \n",
    "        for i in range(nsteps):\n",
    "            norm_i = np.sqrt((r_i ** 2).sum(axis=1))\n",
    "            v_i = r_i[:, [1, 0]] * np.array([-1, 1]) / norm_i[:, np.newaxis]\n",
    "            d_i = timestep * ang_vel_i[:, np.newaxis] * v_i\n",
    "            r_i += d_i\n",
    " \n",
    "        for i, p in enumerate(self.particles):\n",
    "            p.x, p.y = r_i[i]\n",
    " \n",
    "def benchmark(npart=100, method='python'):\n",
    "    particles = [Particle(uniform(-1.0, 1.0), uniform(-1.0, 1.0), uniform(-1.0, 1.0)) for _ in range(npart)]\n",
    "    simulator = ParticleSimulator(particles)\n",
    " \n",
    "    if method == 'python':\n",
    "        simulator.evolve_python(0.1)\n",
    "    elif method == 'numpy':\n",
    "        simulator.evolve_numpy(0.1)\n",
    " \n",
    "# Example of benchmarking\n",
    "if __name__ == \"__main__\":\n",
    "    from timeit import timeit\n",
    " \n",
    "    print(\"Benchmarking with 100 particles:\")\n",
    "    print(\"Python version:\", timeit(\"benchmark(100, 'python')\", globals=globals(), number=1), \"seconds\")\n",
    "    print(\"NumPy version:\", timeit(\"benchmark(100, 'numpy')\", globals=globals(), number=1), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Explain how to optain the optimal performance with numexpr. Read the section. Reaching optimal performance with numexpr, pp. 72 from the previous reference. Implement it and measure the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy accelerates calculations by utilizing array broadcasting and efficient memory use, which becomes particularly advantageous with large data sets, as demonstrated by benchmark comparisons between pure Python and NumPy implementations. \n",
    "\n",
    "The transition from Python loops to NumPy's vectorized operations results in noticeable speed-ups, particularly as the size of the data increases.\n",
    "\n",
    "Numexpr extends these benefits by optimizing array expressions further, reducing memory usage, and utilizing multiple cores for parallel computation. \n",
    "By avoiding intermediate array storage and exploiting CPU cache efficiently, numexpr can significantly speed up operations involving large arrays. \n",
    "\n",
    "This is illustrated in the context of calculating norms and particle displacements where numexpr's capability to compile and optimize complex expressions on-the-fly shows substantial performance enhancements over standard NumPy operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking with 1000 particles:\n",
      "Python version: 2.957614521998039 seconds\n",
      "NumPy version: 0.26057985499937786 seconds\n",
      "NumExpr version: 0.2573370470054215 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import uniform\n",
    "import numexpr as ne\n",
    "\n",
    " \n",
    "class Particle:\n",
    "    def __init__(self, x, y, ang_vel):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.ang_vel = ang_vel\n",
    " \n",
    "class ParticleSimulator:\n",
    "    def __init__(self, particles):\n",
    "        self.particles = particles\n",
    " \n",
    "    def evolve_python(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    " \n",
    "        for i in range(nsteps):\n",
    "            for p in self.particles:\n",
    "                norm = (p.x**2 + p.y**2)**0.5\n",
    "                v_x = (-p.y) / norm\n",
    "                v_y = p.x / norm\n",
    "                d_x = timestep * p.ang_vel * v_x\n",
    "                d_y = timestep * p.ang_vel * v_y\n",
    "                p.x += d_x\n",
    "                p.y += d_y\n",
    " \n",
    "    def evolve_numpy(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    "        r_i = np.array([[p.x, p.y] for p in self.particles])\n",
    "        ang_vel_i = np.array([p.ang_vel for p in self.particles])\n",
    " \n",
    "        for i in range(nsteps):\n",
    "            norm_i = np.sqrt((r_i ** 2).sum(axis=1))\n",
    "            v_i = r_i[:, [1, 0]] * np.array([-1, 1]) / norm_i[:, np.newaxis]\n",
    "            d_i = timestep * ang_vel_i[:, np.newaxis] * v_i\n",
    "            r_i += d_i\n",
    " \n",
    "        for i, p in enumerate(self.particles):\n",
    "            p.x, p.y = r_i[i]\n",
    "\n",
    "    def evolve_numexpr(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    "        r_i = np.array([[p.x, p.y] for p in self.particles])\n",
    "        ang_vel_i = np.array([p.ang_vel for p in self.particles])\n",
    "\n",
    "        for i in range(nsteps):\n",
    "            norm_i = ne.evaluate(\"sqrt((r_i ** 2).sum(axis=1))\")\n",
    "            v_i = r_i[:, [1, 0]]\n",
    "            v_i[:, 0] = ne.evaluate(\"-v_i[:, 0]\")\n",
    "            v_i = ne.evaluate(\"v_i / norm_i[:, None]\")\n",
    "            d_i = ne.evaluate(\"timestep * ang_vel_i[:, None] * v_i\")\n",
    "            r_i = ne.evaluate(\"r_i + d_i\")\n",
    "\n",
    "        for i, p in enumerate(self.particles):\n",
    "            p.x, p.y = r_i[i]\n",
    "\n",
    "def benchmark(npart=100, method='python'):\n",
    "    particles = [Particle(uniform(-1.0, 1.0), uniform(-1.0, 1.0), uniform(-1.0, 1.0)) for _ in range(npart)]\n",
    "    simulator = ParticleSimulator(particles)\n",
    " \n",
    "    if method == 'python':\n",
    "        simulator.evolve_python(0.1)\n",
    "    elif method == 'numpy':\n",
    "        simulator.evolve_numpy(0.1)\n",
    "    elif method == 'numexpr':\n",
    "        simulator.evolve_numpy(0.1)\n",
    "\n",
    "# Example of benchmarking\n",
    "if __name__ == \"__main__\":\n",
    "    from timeit import timeit\n",
    "    \n",
    "    print(\"Benchmarking with 1000 particles:\")\n",
    "    print(\"Python version:\", timeit(\"benchmark(1000, 'python')\", globals=globals(), number=1), \"seconds\")\n",
    "    print(\"NumPy version:\", timeit(\"benchmark(1000, 'numpy')\", globals=globals(), number=1), \"seconds\")\n",
    "    print(\"NumExpr version:\", timeit(\"benchmark(1000, 'numexpr')\", globals=globals(), number=1), \"seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
